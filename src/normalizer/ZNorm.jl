"""
# Summary
    mutable struct ZNorm <: Normalizer
# Fields
    Î³        :: VarOrNil                        # scaling params
    Î²        :: VarOrNil                        # shifting params
    Î¼        :: Union{AbstractArray,Nothing}    # running average
    Ïƒ        :: Union{AbstractArray,Nothing}    # running variance otherwise standard deviation
    views    :: NTuple                          # views to collect elements for mean and var
    training :: Bool                            # if traning or not
    epsilion :: AbstractFloat                   # prevent dividing by zero, 1e-10 for default
    momentum :: AbstractFloat                   # smoothing const, or called historical inertia coefficient

Applies mean and scaling normalization over a N-dimensional input, like BatchNorm LayerNorm and InstanceNorm.

"""
mutable struct ZNorm <: Normalizer
    Î³::VarOrNil                        # scaling params
    Î²::VarOrNil                        # shifting params
    Î¼::Union{AbstractArray,Nothing}    # running average
    Ïƒ::Union{AbstractArray,Nothing}    # running variance otherwise standard deviation
    views::NTuple                      # views to collect elements for mean and var
    training::Bool                     # if traning or not
    epsilion::AbstractFloat            # prevent dividing by zero, 1e-10 for default
    momentum::AbstractFloat            # inertia coefficient
    function ZNorm(;ndims::Int,        # how many dimentions the input data has
                   keptdims::Union{Tuple,Int},     # must be unique and sorted and positive
                   keptsize::Union{Tuple,Int},     # must be positive
                   epsilion::AbstractFloat=1e-10,  # stability const
                   momentum::AbstractFloat=0.900,  # smoothing const or historical inertia
                   type::Type=Array{Float32})

        shape, views = ShapeAndViews(ndims, keptdims, keptsize);
        Î³ = Variable{type}( Ones(type, shape), true, true, true);
        Î² = Variable{type}(Zeros(type, shape), true, true, true);
        Î¼ = Zeros(type, shape);
        Ïƒ =  Ones(type, shape);
        new(Î³, Î², Î¼, Ïƒ, views, true, epsilion, momentum)
    end
    function ZNorm(views, training, epsilion, momentum)
        new(nothing, nothing, nothing, nothing, views, training, epsilion, momentum)
    end
end


function clone(this::ZNorm; type::Type=Array{Float32})
    cloned = ZNorm(this.views, this.training, this.epsilion, this.momentum)
    cloned.Î³ = clone(this.Î³, type=type)
    cloned.Î² = clone(this.Î², type=type)
    cloned.Î¼ = type(this.Î¼)
    cloned.Ïƒ = type(this.Ïƒ)
    return cloned
end

function Base.show(io::IO, m::ZNorm)
    SIZE = size(m.Î².value)
    TYPE = typeof(m.Î².value)
    print(io, "ZNorm(statistic vars' size=$SIZE; type=$TYPE)")
end


function paramsof(m::ZNorm)
    params = Vector{Variable}(undef,2)
    params[1] = m.Î³
    params[2] = m.Î²
    return params
end

function xparamsof(m::ZNorm)
    xparams = Vector{XVariable}(undef,2)
    xparams[1] = ('w', m.Î³)
    xparams[2] = ('b', m.Î²)
    return xparams
end

function nparamsof(model::ZNorm)
    return 4*length(model.Î²)
end

function bytesof(model::ZNorm, unit::String="MB")
    n = nparamsof(model) * sizeof(eltype(model.Î²))
    return blocksize(n, uppercase(unit))
end

function forward(b::ZNorm, x::Variable{T}) where T
    Î³ = b.Î³
    Î² = b.Î²
    Ïµ = b.epsilion
    Ï = b.momentum
    v = b.views
    Î¼ = mean(x.value, dims=v)
    Ïƒ =  std(x.value, dims=v, mean=Î¼, corrected=false)
    ð— = (x.value .- Î¼) ./ (Ïƒ .+ Ïµ)
    y = Variable{T}(ð— .* Î³.value .+ Î².value, x.backprop)

    if y.backprop
        Î£ = Ïƒ .* Ïƒ
        @. b.Î¼ = Ï * b.Î¼ + (1 - Ï) * Î¼    # running mean
        @. b.Ïƒ = Ï * b.Ïƒ + (1 - Ï) * Î£    # running var
        function ZNormBackward()
            if need2computeÎ´!(x)
                n     = length(Ïƒ)/length(x)
                ÏƒÂ¯Â¹   = 1 ./ (Ïƒ .+ Ïµ)
                ÏƒÂ¯Â³   = (ÏƒÂ¯Â¹).^3
                Î“     = Î³.value
                Î”     = x.value .- Î¼
                âˆ‚ð‹âˆ‚ð—  = y.delta .* Î“
                Î”âˆ‚ð‹âˆ‚ð— = Î” .* âˆ‚ð‹âˆ‚ð—
                SumÎ”âˆ‚ð‹âˆ‚ð—  = sum(Î”âˆ‚ð‹âˆ‚ð—, dims=v)

                x.delta .+= ÏƒÂ¯Â¹ .* âˆ‚ð‹âˆ‚ð—
                x.delta .-= ÏƒÂ¯Â³ .* n   .* SumÎ”âˆ‚ð‹âˆ‚ð— .* Î”
                x.delta .+= ÏƒÂ¯Â³ .* n^2 .* SumÎ”âˆ‚ð‹âˆ‚ð— .* sum(Î”, dims=v) .- ÏƒÂ¯Â¹ .* n .* sum(âˆ‚ð‹âˆ‚ð—, dims=v)

                if need2computeÎ´!(Î³) Î³.delta .+= sum(y.delta .* ð—, dims=v) end
                if need2computeÎ´!(Î²) Î².delta .+= sum(y.delta,      dims=v) end
            end
            ifNotKeepÎ´ThenFreeÎ´!(y);
        end
        push!(graph.backward, ZNormBackward)
    end
    return y
end


function predict(b::ZNorm, x::AbstractArray)
    Ïµ = b.epsilion
    Î³ = b.Î³.value
    Î² = b.Î².value
    Î¼ = b.Î¼
    Ïƒ = b.Ïƒ
    return @. (x - Î¼) / sqrt(Ïƒ + Ïµ) * Î³ + Î²
end


function BatchNorm1d(nchannels::Int;
            epsilion::AbstractFloat=1e-10,
            momentum::AbstractFloat=0.900,
            type::Type=Array{Float32})
    return ZNorm(ndims=3,
                 keptdims=1,
                 keptsize=nchannels,
                 epsilion=epsilion,
                 momentum=momentum,
                 type=type)
end


function BatchNorm0d(nchannels::Int;
            epsilion::AbstractFloat=1e-10,
            momentum::AbstractFloat=0.900,
            type::Type=Array{Float32})
    return ZNorm(ndims=2,
                 keptdims=1,
                 keptsize=nchannels,
                 epsilion=epsilion,
                 momentum=momentum,
                 type=type)
end
