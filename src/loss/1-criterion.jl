export loss
export cost


# Internal function
function _sum(x::Variable{T}) where T
    y = Variable{T}([sum(áµ›(x))], x.backprop)
    if x.backprop
        function _sumBackward()
            if need2computeÎ´!(x)
                Î´(x) .+= Î´(y)
            end
            ifNotKeepÎ´ThenFreeÎ´!(y)
        end
        push!(graph.backward, _sumBackward)
    end
    return y
end


# Internal function
function _mean(x::Variable{T}) where T
    n = eltype(x)(1) / prod(size(x))
    Î¼ = Variable{T}([sum(áµ›(x)) * n], x.backprop)
    if x.backprop
        function _meanBackward()
            if need2computeÎ´!(x)
                Î´(x) .+= Î´(Î¼) .* n
            end
            ifNotKeepÎ´ThenFreeÎ´!(Î¼);
        end
        push!(graph.backward, _meanBackward)
    end
    return Î¼
end


"""
    loss(x::Variable{T}; reduction::String="sum") -> y::Variable{T}

Sums or takes mean over all elements in `value` of `x` as the loss `Variable`, i.e. â¤¦\n
+ `y = Variable{T}([sum(áµ›(x))], x.backprop)`, if reduction="sum"
+ `y = Variable{T}([sum(áµ›(x))/length(x)], x.backprop)`, if reduction="mean"
This is very convenient for mutiple loss training. e.g. â¤¦\n
    totalLoss = Î²*loss(mse(xâ‚, Ì‚xâ‚)) + (1 - Î²)*loss(crossEntropy(yâ‚, Ì‚yâ‚))
or in a lazy way:\n
    totalLoss = Î²*mseLoss(xâ‚, Ì‚xâ‚) + (1 - Î²)*crossEntropyLoss(yâ‚, Ì‚yâ‚)
where `Î²` is weight of mseLoss function.
"""
function loss(x::Variable{T}; reduction::String="sum") where T
    by = lowercase(reduction)
    by=="sum" && return _sum(x)
    by=="mean" && return _mean(x)
    @error "wrong reduction method" reduction=="sum" || reduction=="mean"
end


"""
    cost(x::Variable) -> y::eltype(x)

sums over all elements in `value` of `x` as the final loss value which is a scalar, i.e. â¤¦\n
    y = sum(x.value), so Î´(x) = âˆ‚y/âˆ‚x = ğŸ™
"""
function cost(x::Variable{T}) where T
    if x.backprop
        ğŸ™ = eltype(x)(1.0)
        function costBackward()
            if need2computeÎ´!(x)
                Î´(x) .+= ğŸ™
            end
        end
        push!(graph.backward, costBackward)
    end
    return sum(áµ›(x))
end


include("./1-criterion-regression.jl")
include("./1-criterion-probabilistic.jl")
